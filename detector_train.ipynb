{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "tqdm.pandas(desc='pandas bar')\n",
    "# from pandarallel import pandarallel\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "import logging\n",
    "# pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "from ditto.model import DittoModel,DittoDataset,load_model,to_str,classify,train,simple_train,simple_train_update\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set for CUDA_VISIBLE_DEVICES, only single card is supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "hp_simple = SimpleNamespace(task='hospital-detector-train',\n",
    "                     batch_size=64,\n",
    "                     max_len=128,\n",
    "                     lr=3e-5,\n",
    "                     n_epochs=20,\n",
    "                     save_model=True,\n",
    "                     logdir=\"detector_model/\", ## Checkpoint save path\n",
    "                     lm='roberta-base', ## roberta-base model, please change to your own model path\n",
    "                     fp16=True,\n",
    "                     alpha_aug=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Training/Inferencing data\n",
    "\n",
    "dataloader takes 3-column (text0-text1-label) DataFrame as input\n",
    "\n",
    "replace `dataset` to your target dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = pd.read_csv('GEIL_Data/dataset/detector/train.csv',index_col=0).astype(str)\n",
    "\n",
    "valid_output = pd.read_csv('GEIL_Data/dataset/detector/train.csv',index_col=0).astype(str)\n",
    "\n",
    "test_output = pd.read_csv('GEIL_Data/dataset/detector/test.csv',index_col=0).astype(str)\n",
    "train_dataset = DittoDataset(train_output,max_len=128,lm = 'roberta-base')\n",
    "valid_dataset = DittoDataset(valid_output,max_len=128,lm = 'roberta-base')\n",
    "test_dataset = DittoDataset(test_output,max_len=128,lm = 'roberta-base')\n",
    "test_dataset_all = DittoDataset(test_output,max_len=128,lm = 'roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = simple_train(train_dataset,valid_dataset,test_dataset,hp_simple) ## Training\n",
    "import time\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "start_time = time.time()\n",
    "predict = classify(test_dataset_all,model=model_output,lm='roberta-base',max_len=128,threshold=0.5) ## Inference\n",
    "# result_f1 = f1_score(y_pred=predict[0],y_true=test_all.iloc[:,-1].astype(int))\n",
    "# print('episode_%s Task: %s f1-score: %s' % ('0','rayyan-init-20',str(result_f1)))\n",
    "end_time = time.time()\n",
    "print(f\"inference timeï¼š{end_time - start_time} s\")\n",
    "print(\"prec: \", precision_score(y_pred=predict[0],y_true=test_all.iloc[:,-1].astype(int)), \" recall: \",  recall_score(y_pred=predict[0],y_true=test_all.iloc[:,-1].astype(int)), \", f1: \", f1_score(y_pred=predict[0],y_true=test_all.iloc[:,-1].astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For result to detector\n",
    "- the predict result is 1-d array, you should reshape to (row_num,-1) to fit for dirty.csv shape\n",
    "- `beers` dataset, we omit the first 2 columns\n",
    "- `rayyan` dataset, we omit the first 1 columns\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(predict[0]).reshape((-1,6)) ## reshape to match the dirty.csv shape\n",
    "\n",
    "\n",
    "np.save('GEIL_Data/dataset/detector/detector.npy',result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
